Draft: Technical Report Outline
Title: Improving National Water Model Runoff Forecasts using a Sequence-to-Sequence LSTM Error Correction Model

Authors: [Your Name(s)]

Abstract: (Write this last - ~150-250 words summarizing the problem, methods, key results, and conclusion)

Example Snippets: Accurate runoff forecasting is crucial... The National Water Model (NWM) provides valuable forecasts but exhibits errors... This study applies a Sequence-to-Sequence (Seq2Seq) LSTM neural network to predict and correct NWM forecast errors for lead times 1-18 hours simultaneously... Data from USGS and NWM for two stations (20380357, 21609641) from April 2021 to April 2023 were used... The model was trained on historical observations, NWM forecasts, and forecast errors, using TimeSeriesSplit cross-validation for hyperparameter tuning... Results on a held-out test set (Oct 2022 - Apr 2023) show the Seq2Seq model [mention key finding, e.g., significantly reduced RMSE/improved NSE compared to raw NWM and a persistence baseline, especially for leads X-Y hours]... This demonstrates the potential of DL post-processing...*
1. Introduction * Importance of accurate streamflow/runoff forecasting (water management, flood prediction). * Overview of the National Water Model (NWM) and its role. * Common challenges with physics-based models like NWM (systematic errors, time-dependent errors). * Introduction to Deep Learning (DL) for hydrological post-processing. * Potential of Sequence-to-Sequence (Seq2Seq) LSTMs for time-series error correction (cite Han & Morrison, 2022). * Project Objective: Develop and evaluate a Seq2Seq LSTM model to predict and correct NWM forecast errors (1-18h leads) for two specific USGS stations. * Structure of the report.

2. Data and Methods * 2.1 Data Sources * NWM short-range forecasts (source, variables, temporal resolution - hourly, lead times 1-18h). * USGS observed runoff data (source, variables, temporal resolution - hourly). * Specific Stations: Mention IDs (20380357, 21609641). * Time Period: April 2021 – April 2023. * 2.2 Data Splitting * Training/Validation Set: April 2021 – September 2022. * Test Set: October 2022 – April 2023 (strictly held-out). * Rationale: Temporal split to prevent data leakage and mimic operational forecasting. * 2.3 Data Preprocessing * Loading data (mention file structure: data/raw/, data/processed/). * Cleaning: Handling missing values (initial check), timestamp alignment, timezone standardization (if applicable). * NWM Forecast Error Calculation: Error[lead] = NWM_Forecast[lead] - USGS_Observed. * Alignment: Describe the process of merging USGS data with NWM forecasts for all lead times (mention the dropna() step and its impact - e.g., ~75% rows dropped, reference terminal output #1). * Feature Scaling: StandardScaler fit only on the training+validation data, applied to both train/val and test sets. * 2.4 Feature Engineering (Seq2Seq Structure) * Sequence Length: Define (e.g., 24 hours). * Encoder Input: Past sequence_length hours of [USGS observed, NWM 1h forecast, NWM 1h error]. * Decoder Input: NWM forecasts for leads 1-18h issued at the current time step. * Target Output: Actual NWM forecast errors for leads 1-18h over the next 18 hours. * 2.5 Baseline Model * Description: Simple persistence model for error correction (e.g., Predicted_Errorlead = Observed_Errorlead). * Purpose: Provide a simple benchmark for the Seq2Seq model. * 2.6 Seq2Seq LSTM Model * Architecture: Encoder-Decoder framework using LSTM layers. Mention activation (ReLU) and optimizer (Adam). * Input/Output Shapes: Define based on features and sequence lengths (reference terminal output #1). * Training Objective: Minimize loss (e.g., MSE) between predicted errors and actual errors across all 18 lead times. * 2.7 Hyperparameter Tuning * Tool: keras_tuner (HyperBand or BayesianOptimization). * Validation Strategy: sklearn.model_selection.TimeSeriesSplit applied to the training+validation set. * Parameters Tuned: LSTM units, learning rate, dropout rate, sequence length (if varied), number of layers. * 2.8 Evaluation * Metrics: Coefficient of Correlation (CC), Root Mean Square Error (RMSE), Percent Bias (PBIAS), Nash-Sutcliffe Efficiency (NSE). * Calculation: Metrics computed for each lead time (1-18h) on the test set. * Comparison: Evaluate Raw NWM, Baseline Corrected, and Seq2Seq Corrected forecasts against USGS Observations. * 2.9 Implementation Details * Software: Python, TensorFlow/Keras, Pandas, Scikit-learn, Matplotlib, Seaborn, KerasTuner. * Code Repository: Link to GitHub repository (as required).

3. Results * 3.1 Preprocessing Summary: Briefly mention final data shapes for train/test sets per stream (reference terminal output #1). * 3.2 Hyperparameter Tuning: Report the best hyperparameters found by KerasTuner. * 3.3 Model Performance on Test Set * Present Figure 1: Box-plot of Runoff (Observed vs. NWM vs. Baseline Corrected vs. Seq2Seq Corrected) per lead time. Describe key visual differences. * Present Figure 2: Box-plots of Evaluation Metrics (CC, RMSE, PBIAS, NSE) per lead time, comparing NWM, Baseline, and Seq2Seq. Describe trends across lead times for each metric. * (Optional) Table summarizing average metrics or metrics at specific lead times (e.g., 1h, 6h, 12h, 18h). * Narrative description comparing Seq2Seq performance against NWM and Baseline based on the figures/tables.

4. Discussion * Interpretation of results: Did the Seq2Seq model achieve the goal? How significant was the improvement over NWM and the baseline? Was performance consistent across lead times and stations? * Impact of data preprocessing: Discuss the effect of dropping rows with missing data. * Model limitations: Complexity, training time, potential overfitting (despite validation), sensitivity to hyperparameters, limited geographical scope (two stations). * Challenges encountered (e.g., data alignment, computational resources). * Comparison to literature (briefly, e.g., Han & Morrison). * Future Work: Test on more stations, explore different architectures (e.g., Attention, Transformers), incorporate more input features (e.g., precipitation), investigate imputation methods, deploy operationally.

5. Conclusion * Summarize the key findings (e.g., Seq2Seq LSTM effectively corrects NWM errors...). * Reiterate the significance and potential application of the approach.

References * Han, H., & Morrison, R. R. (2022)... * List other relevant papers, software packages (TensorFlow, Keras, Pandas, etc.).

Appendix (Optional) * Detailed hyperparameter tuning setup/results. * Full tables of metrics per lead time. * Additional diagnostic plots.