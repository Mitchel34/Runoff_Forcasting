{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075cb914",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of NWM and USGS Time Series\n",
    "\n",
    "This notebook performs exploratory analysis of the National Water Model (NWM) forecasts and USGS observed runoff data.\n",
    "\n",
    "## Objectives:\n",
    "1. Understand the structure and properties of the data\n",
    "2. Identify patterns and trends in NWM forecasts and USGS observations\n",
    "3. Visualize forecast errors across different lead times\n",
    "4. Evaluate data quality issues such as missing values and outliers\n",
    "5. Identify potential features for model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82fa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a8f43",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Inspection\n",
    "\n",
    "First, let's load the USGS observed data and NWM forecast data for both streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188502ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/CS 4440 AI/Runoff_Forcasting/Runoff_Forcasting/nwm_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stream_id \u001b[38;5;129;01min\u001b[39;00m stream_ids:\n\u001b[0;32m---> 38\u001b[0m     usgs_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_usgs_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     nwm_df \u001b[38;5;241m=\u001b[39m load_nwm_data(stream_id)\n\u001b[1;32m     40\u001b[0m     data[stream_id] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musgs\u001b[39m\u001b[38;5;124m\"\u001b[39m: usgs_df,\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnwm\u001b[39m\u001b[38;5;124m\"\u001b[39m: nwm_df\n\u001b[1;32m     43\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_usgs_data\u001b[0;34m(stream_id)\u001b[0m\n\u001b[1;32m     11\u001b[0m usgs_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(usgs_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Convert to datetime\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m usgs_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43musgs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     14\u001b[0m usgs_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m usgs_df\n",
      "File \u001b[0;32m~/Desktop/CS 4440 AI/Runoff_Forcasting/Runoff_Forcasting/nwm_env/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/CS 4440 AI/Runoff_Forcasting/Runoff_Forcasting/nwm_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_path = \"../data/raw\"\n",
    "stream_ids = [\"20380357\", \"21609641\"]\n",
    "\n",
    "# Function to load USGS data\n",
    "def load_usgs_data(stream_id):\n",
    "    usgs_files = glob(os.path.join(data_path, str(stream_id), \"*_Strt_*.csv\"))\n",
    "    if not usgs_files:\n",
    "        raise FileNotFoundError(f\"No USGS data files found for stream {stream_id}\")\n",
    "    \n",
    "    usgs_df = pd.read_csv(usgs_files[0])\n",
    "    # Convert to datetime\n",
    "    usgs_df['datetime'] = pd.to_datetime(usgs_df['datetime'])\n",
    "    usgs_df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    return usgs_df\n",
    "\n",
    "# Function to load NWM data\n",
    "def load_nwm_data(stream_id):\n",
    "    nwm_files = glob(os.path.join(data_path, str(stream_id), \"streamflow_*.csv\"))\n",
    "    if not nwm_files:\n",
    "        raise FileNotFoundError(f\"No NWM data files found for stream {stream_id}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for file in nwm_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    nwm_df = pd.concat(dfs, ignore_index=True)\n",
    "    nwm_df['reference_time'] = pd.to_datetime(nwm_df['reference_time'])\n",
    "    nwm_df['value_time'] = pd.to_datetime(nwm_df['value_time'])\n",
    "    \n",
    "    return nwm_df\n",
    "\n",
    "# Load data for each stream\n",
    "data = {}\n",
    "for stream_id in stream_ids:\n",
    "    usgs_df = load_usgs_data(stream_id)\n",
    "    nwm_df = load_nwm_data(stream_id)\n",
    "    data[stream_id] = {\n",
    "        \"usgs\": usgs_df,\n",
    "        \"nwm\": nwm_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca060e",
   "metadata": {},
   "source": [
    "## 2. Examining Data Structure\n",
    "\n",
    "Let's take a look at the structure and contents of both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream ID to examine\n",
    "stream_id = stream_ids[0]  # First stream\n",
    "\n",
    "print(\"USGS Data Structure:\")\n",
    "print(data[stream_id][\"usgs\"].head())\n",
    "print(\"\\nUSGS Data Info:\")\n",
    "print(data[stream_id][\"usgs\"].info())\n",
    "print(\"\\nUSGS Data Statistics:\")\n",
    "print(data[stream_id][\"usgs\"].describe())\n",
    "\n",
    "print(\"\\n\\nNWM Data Structure:\")\n",
    "print(data[stream_id][\"nwm\"].head())\n",
    "print(\"\\nNWM Data Info:\")\n",
    "print(data[stream_id][\"nwm\"].info())\n",
    "print(\"\\nNWM Data Statistics by Lead Time:\")\n",
    "print(data[stream_id][\"nwm\"].groupby(\"lead_time\")[\"streamflow\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363a262",
   "metadata": {},
   "source": [
    "## 3. Temporal Coverage and Availability\n",
    "\n",
    "Let's examine the temporal coverage and availability of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream_id in stream_ids:\n",
    "    usgs_df = data[stream_id][\"usgs\"]\n",
    "    nwm_df = data[stream_id][\"nwm\"]\n",
    "    \n",
    "    print(f\"Stream {stream_id} - USGS Data:\")\n",
    "    print(f\"Start date: {usgs_df.index.min()}\")\n",
    "    print(f\"End date: {usgs_df.index.max()}\")\n",
    "    print(f\"Total records: {len(usgs_df)}\")\n",
    "    print(f\"Missing values: {usgs_df.isna().sum().sum()}\")\n",
    "    \n",
    "    print(f\"\\nStream {stream_id} - NWM Data:\")\n",
    "    print(f\"Start reference time: {nwm_df['reference_time'].min()}\")\n",
    "    print(f\"End reference time: {nwm_df['reference_time'].max()}\")\n",
    "    print(f\"Start value time: {nwm_df['value_time'].min()}\")\n",
    "    print(f\"End value time: {nwm_df['value_time'].max()}\")\n",
    "    print(f\"Total records: {len(nwm_df)}\")\n",
    "    print(f\"Missing values: {nwm_df.isna().sum().sum()}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aebd59c",
   "metadata": {},
   "source": [
    "## 4. Data Distribution Analysis\n",
    "\n",
    "Let's visualize the distribution of runoff values in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "for i, stream_id in enumerate(stream_ids):\n",
    "    usgs_df = data[stream_id][\"usgs\"]\n",
    "    nwm_df = data[stream_id][\"nwm\"]\n",
    "    \n",
    "    # Histogram of USGS observed runoff\n",
    "    ax = axes[i, 0]\n",
    "    ax.hist(usgs_df['value'], bins=50, alpha=0.7)\n",
    "    ax.set_title(f\"Stream {stream_id} - USGS Observed Runoff Distribution\")\n",
    "    ax.set_xlabel(\"Runoff\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "    # Histogram of NWM forecast runoff by lead time\n",
    "    ax = axes[i, 1]\n",
    "    lead_times = [1, 6, 12, 18]  # Representative lead times\n",
    "    for lead in lead_times:\n",
    "        lead_data = nwm_df[nwm_df['lead_time'] == lead]['streamflow']\n",
    "        ax.hist(lead_data, bins=50, alpha=0.4, label=f\"Lead {lead}h\")\n",
    "    \n",
    "    ax.set_title(f\"Stream {stream_id} - NWM Forecast Runoff Distribution by Lead Time\")\n",
    "    ax.set_xlabel(\"Runoff\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ed814",
   "metadata": {},
   "source": [
    "## 5. Time Series Visualization\n",
    "\n",
    "Let's visualize the time series data to understand patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure NWM data to align with USGS observations\n",
    "def align_nwm_with_usgs(stream_id, lead_times=[1, 6, 12, 18]):\n",
    "    usgs_df = data[stream_id][\"usgs\"]\n",
    "    nwm_df = data[stream_id][\"nwm\"]\n",
    "    \n",
    "    aligned_data = {}\n",
    "    aligned_data['usgs'] = usgs_df['value']\n",
    "    \n",
    "    for lead in lead_times:\n",
    "        # Filter for this lead time\n",
    "        lead_df = nwm_df[nwm_df['lead_time'] == lead].copy()\n",
    "        # Set index to value_time (when the forecast is for)\n",
    "        lead_df.set_index('value_time', inplace=True)\n",
    "        # Get the streamflow column\n",
    "        lead_series = lead_df['streamflow']\n",
    "        # Add to aligned data with a descriptive name\n",
    "        aligned_data[f'nwm_lead_{lead}'] = lead_series\n",
    "    \n",
    "    # Combine into one DataFrame\n",
    "    return pd.DataFrame(aligned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aligned data for visualization\n",
    "for stream_id in stream_ids:\n",
    "    aligned_df = align_nwm_with_usgs(stream_id)\n",
    "    \n",
    "    # Plot time series for a 3-month period\n",
    "    sample_start = pd.Timestamp('2022-01-01')\n",
    "    sample_end = pd.Timestamp('2022-04-01')\n",
    "    sample_df = aligned_df.loc[sample_start:sample_end]\n",
    "    \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.plot(sample_df.index, sample_df['usgs'], label='USGS Observed', linewidth=2)\n",
    "    for lead in [1, 6, 12, 18]:\n",
    "        plt.plot(sample_df.index, sample_df[f'nwm_lead_{lead}'], \n",
    "                 label=f'NWM Lead {lead}h', alpha=0.7)\n",
    "    \n",
    "    plt.title(f\"Stream {stream_id} - Observed vs. Forecast Runoff (Jan-Mar 2022)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Runoff\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6daf7",
   "metadata": {},
   "source": [
    "## 6. Forecast Error Analysis\n",
    "\n",
    "Let's calculate and visualize the errors in the NWM forecasts compared to USGS observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d849392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forecast errors\n",
    "for stream_id in stream_ids:\n",
    "    aligned_df = align_nwm_with_usgs(stream_id, lead_times=range(1, 19))\n",
    "    \n",
    "    # Add error columns\n",
    "    for lead in range(1, 19):\n",
    "        if f'nwm_lead_{lead}' in aligned_df.columns:\n",
    "            aligned_df[f'error_lead_{lead}'] = aligned_df[f'nwm_lead_{lead}'] - aligned_df['usgs']\n",
    "    \n",
    "    # Plot error distributions for selected lead times\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    lead_times = [1, 6, 12, 18]\n",
    "    for i, lead in enumerate(lead_times):\n",
    "        if f'error_lead_{lead}' in aligned_df.columns:\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            sns.histplot(aligned_df[f'error_lead_{lead}'].dropna(), kde=True)\n",
    "            plt.title(f\"Stream {stream_id} - Error Distribution (Lead {lead}h)\")\n",
    "            plt.xlabel(\"Forecast Error (NWM - USGS)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot error vs lead time\n",
    "    error_means = [aligned_df[f'error_lead_{lead}'].mean() for lead in range(1, 19) if f'error_lead_{lead}' in aligned_df.columns]\n",
    "    error_stds = [aligned_df[f'error_lead_{lead}'].std() for lead in range(1, 19) if f'error_lead_{lead}' in aligned_df.columns]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.errorbar(range(1, len(error_means)+1), error_means, yerr=error_stds, fmt='o-')\n",
    "    plt.title(f\"Stream {stream_id} - Mean Forecast Error by Lead Time\")\n",
    "    plt.xlabel(\"Lead Time (hours)\")\n",
    "    plt.ylabel(\"Mean Error (NWM - USGS)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbdf1b2",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "Let's investigate the correlation between observed values and forecasts at different lead times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "for stream_id in stream_ids:\n",
    "    aligned_df = align_nwm_with_usgs(stream_id, lead_times=range(1, 19))\n",
    "    \n",
    "    correlations = []\n",
    "    lead_times = []\n",
    "    \n",
    "    for lead in range(1, 19):\n",
    "        col = f'nwm_lead_{lead}'\n",
    "        if col in aligned_df.columns:\n",
    "            # Drop any NaN values\n",
    "            valid_data = aligned_df[['usgs', col]].dropna()\n",
    "            if len(valid_data) > 0:\n",
    "                corr, _ = stats.pearsonr(valid_data['usgs'], valid_data[col])\n",
    "                correlations.append(corr)\n",
    "                lead_times.append(lead)\n",
    "    \n",
    "    # Plot correlation vs lead time\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(lead_times, correlations, 'o-')\n",
    "    plt.title(f\"Stream {stream_id} - Correlation between Observed and Forecast Runoff\")\n",
    "    plt.xlabel(\"Lead Time (hours)\")\n",
    "    plt.ylabel(\"Pearson Correlation Coefficient\")\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be145656",
   "metadata": {},
   "source": [
    "## 8. Seasonal Patterns in Forecast Errors\n",
    "\n",
    "Let's investigate if there are seasonal patterns in the forecast errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab23871",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream_id in stream_ids:\n",
    "    aligned_df = align_nwm_with_usgs(stream_id)\n",
    "    \n",
    "    # Add month column\n",
    "    aligned_df['month'] = aligned_df.index.month\n",
    "    \n",
    "    # Calculate mean errors by month for different lead times\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, lead in enumerate([1, 6, 12, 18]):\n",
    "        if f'error_lead_{lead}' in aligned_df.columns:\n",
    "            monthly_errors = aligned_df.groupby('month')[f'error_lead_{lead}'].mean()\n",
    "            plt.plot(monthly_errors.index, monthly_errors.values, 'o-', \n",
    "                     label=f'Lead {lead}h')\n",
    "    \n",
    "    plt.title(f\"Stream {stream_id} - Monthly Mean Forecast Error\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Mean Error (NWM - USGS)\")\n",
    "    plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                             'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d57ac",
   "metadata": {},
   "source": [
    "## 9. Autocorrelation Analysis of Forecast Errors\n",
    "\n",
    "Let's investigate the autocorrelation in forecast errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc875be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "for stream_id in stream_ids:\n",
    "    aligned_df = align_nwm_with_usgs(stream_id)\n",
    "    \n",
    "    # Plot autocorrelation for errors at different lead times\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, lead in enumerate([1, 6, 12, 18]):\n",
    "        if f'error_lead_{lead}' in aligned_df.columns:\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            autocorrelation_plot(aligned_df[f'error_lead_{lead}'].dropna())\n",
    "            plt.title(f\"Stream {stream_id} - Error Autocorrelation (Lead {lead}h)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d34cb",
   "metadata": {},
   "source": [
    "## 10. Error Persistence Analysis\n",
    "\n",
    "Let's analyze whether errors are persistent across lead times, which would indicate potential advantages for the baseline persistence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream_id in stream_ids:\n",
    "    aligned_df = align_nwm_with_usgs(stream_id, lead_times=range(1, 19))\n",
    "    \n",
    "    # Calculate errors\n",
    "    for lead in range(1, 19):\n",
    "        col = f'nwm_lead_{lead}'\n",
    "        if col in aligned_df.columns:\n",
    "            aligned_df[f'error_lead_{lead}'] = aligned_df[col] - aligned_df['usgs']\n",
    "    \n",
    "    # Calculate correlation between errors at different lead times\n",
    "    error_cols = [col for col in aligned_df.columns if col.startswith('error_lead_')]\n",
    "    if error_cols:\n",
    "        error_corr = aligned_df[error_cols].corr()\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(error_corr, annot=True, cmap='coolwarm', fmt='.2f', \n",
    "                   linewidths=0.5, square=True)\n",
    "        plt.title(f\"Stream {stream_id} - Error Correlation Matrix\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bb776",
   "metadata": {},
   "source": [
    "## 11. Summary of Findings\n",
    "\n",
    "Based on our exploratory data analysis, we can make the following observations:\n",
    "\n",
    "1. **Data Coverage**: [Observations about temporal coverage and completeness]\n",
    "2. **Error Distribution**: [Observations about error distributions across lead times]\n",
    "3. **Seasonal Patterns**: [Observations about seasonal patterns in errors]\n",
    "4. **Error Persistence**: [Observations about error persistence across lead times]\n",
    "5. **Correlation**: [Observations about correlation between observed and forecast values]\n",
    "\n",
    "These findings will inform our approach to model development and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ac431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
