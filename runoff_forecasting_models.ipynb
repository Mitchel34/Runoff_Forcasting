{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a63397d",
   "metadata": {},
   "source": [
    "# Runoff Forecasting using LSTM and Transformer Models\n",
    "\n",
    "This notebook implements and evaluates LSTM and Transformer models for runoff forecasting at two different stations (21609641 and 20380357)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5755a",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "Import libraries such as NumPy, Pandas, Matplotlib, TensorFlow, and potentially PyTorch for data handling, visualization, and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# import torch # Uncomment if using PyTorch\n",
    "\n",
    "# Evaluation metrics (if not using standard libraries)\n",
    "# from sklearn.metrics import mean_squared_error, r2_score # Example\n",
    "# Define custom metrics if needed (e.g., NSE, PBIAS, CC)\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "# print(\"PyTorch Version:\", torch.__version__) # Uncomment if using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03acd4",
   "metadata": {},
   "source": [
    "## Load and Explore Data\n",
    "Load the raw and processed data for both stations. Perform exploratory data analysis to understand patterns and anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths (adjust as necessary)\n",
    "raw_data_path_s1 = 'path/to/raw_data_station_21609641.csv'\n",
    "processed_data_path_s1 = 'path/to/processed_data_station_21609641.csv'\n",
    "raw_data_path_s2 = 'path/to/raw_data_station_20380357.csv'\n",
    "processed_data_path_s2 = 'path/to/processed_data_station_20380357.csv'\n",
    "\n",
    "# Load data (assuming CSV format)\n",
    "try:\n",
    "    # Station 1 (LSTM)\n",
    "    # df_raw_s1 = pd.read_csv(raw_data_path_s1, index_col='datetime', parse_dates=True)\n",
    "    df_processed_s1 = pd.read_csv(processed_data_path_s1, index_col='datetime', parse_dates=True)\n",
    "    print(\"Loaded processed data for Station 21609641:\")\n",
    "    print(df_processed_s1.head())\n",
    "    print(df_processed_s1.info())\n",
    "    print(df_processed_s1.describe())\n",
    "\n",
    "    # Station 2 (Transformer)\n",
    "    # df_raw_s2 = pd.read_csv(raw_data_path_s2, index_col='datetime', parse_dates=True)\n",
    "    df_processed_s2 = pd.read_csv(processed_data_path_s2, index_col='datetime', parse_dates=True)\n",
    "    print(\"\\nLoaded processed data for Station 20380357:\")\n",
    "    print(df_processed_s2.head())\n",
    "    print(df_processed_s2.info())\n",
    "    print(df_processed_s2.describe())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Data files not found. Please check the file paths.\")\n",
    "    # Create dummy data for demonstration if files are missing\n",
    "    dates_s1 = pd.date_range(start='2010-01-01', end='2015-12-31', freq='D')\n",
    "    df_processed_s1 = pd.DataFrame({\n",
    "        'nwm_forecast_lead_1': np.random.rand(len(dates_s1)) * 100,\n",
    "        'nwm_forecast_lead_2': np.random.rand(len(dates_s1)) * 100,\n",
    "        'usgs_observation': np.random.rand(len(dates_s1)) * 100 + 5\n",
    "    }, index=dates_s1)\n",
    "    print(\"\\nUsing dummy data for Station 21609641.\")\n",
    "\n",
    "    dates_s2 = pd.date_range(start='2010-01-01', end='2015-12-31', freq='D')\n",
    "    df_processed_s2 = pd.DataFrame({\n",
    "        'nwm_forecast_lead_1': np.random.rand(len(dates_s2)) * 50,\n",
    "        'nwm_forecast_lead_2': np.random.rand(len(dates_s2)) * 50,\n",
    "        'usgs_observation': np.random.rand(len(dates_s2)) * 50 + 3\n",
    "    }, index=dates_s2)\n",
    "    print(\"Using dummy data for Station 20380357.\")\n",
    "\n",
    "\n",
    "# --- Exploratory Data Analysis ---\n",
    "\n",
    "# Example: Plot time series for one station\n",
    "if 'df_processed_s1' in locals():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_processed_s1.index, df_processed_s1['usgs_observation'], label='USGS Observation (S1)')\n",
    "    plt.plot(df_processed_s1.index, df_processed_s1['nwm_forecast_lead_1'], label='NWM Forecast Lead 1 (S1)', alpha=0.7)\n",
    "    plt.title('Station 21609641 - Observed vs. NWM Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Runoff')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if 'df_processed_s2' in locals():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_processed_s2.index, df_processed_s2['usgs_observation'], label='USGS Observation (S2)')\n",
    "    plt.plot(df_processed_s2.index, df_processed_s2['nwm_forecast_lead_1'], label='NWM Forecast Lead 1 (S2)', alpha=0.7)\n",
    "    plt.title('Station 20380357 - Observed vs. NWM Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Runoff')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Add more EDA as needed (histograms, correlation matrices, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f94057",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "Implement data preprocessing steps, including cleaning, aligning NWM forecasts with USGS observations, creating input-output sequences, and splitting data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Configuration ---\n",
    "SEQUENCE_LENGTH = 10 # Example: Use past 10 days to predict next day\n",
    "TARGET_LEAD_TIME = 1 # Example: Predict 1 day ahead\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.1 # Fraction of training data to use for validation\n",
    "\n",
    "# --- Helper Function for Sequence Creation ---\n",
    "def create_sequences(input_data, target_data, sequence_length):\n",
    "    \"\"\"Creates input sequences and corresponding targets.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(input_data) - sequence_length):\n",
    "        X.append(input_data[i:(i + sequence_length)])\n",
    "        y.append(target_data[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- Preprocessing for Station 1 (LSTM) ---\n",
    "if 'df_processed_s1' in locals():\n",
    "    print(\"\\nPreprocessing Station 21609641...\")\n",
    "    # Select features and target\n",
    "    # Assuming NWM forecasts are features and USGS observation is target\n",
    "    features_s1 = df_processed_s1[['nwm_forecast_lead_1', 'nwm_forecast_lead_2']].values # Add more features if available\n",
    "    target_s1 = df_processed_s1['usgs_observation'].values.reshape(-1, 1)\n",
    "\n",
    "    # Scale features and target (important for NNs)\n",
    "    scaler_features_s1 = MinMaxScaler()\n",
    "    features_scaled_s1 = scaler_features_s1.fit_transform(features_s1)\n",
    "\n",
    "    scaler_target_s1 = MinMaxScaler()\n",
    "    target_scaled_s1 = scaler_target_s1.fit_transform(target_s1)\n",
    "\n",
    "    # Create sequences\n",
    "    X_s1, y_s1 = create_sequences(features_scaled_s1, target_scaled_s1.flatten(), SEQUENCE_LENGTH)\n",
    "    print(f\"Station 1 - X shape: {X_s1.shape}, y shape: {y_s1.shape}\")\n",
    "\n",
    "    # Split data (chronological split is often preferred for time series)\n",
    "    split_idx_test_s1 = int(len(X_s1) * (1 - TEST_SIZE))\n",
    "    split_idx_val_s1 = int(split_idx_test_s1 * (1 - VALIDATION_SIZE))\n",
    "\n",
    "    X_train_s1, y_train_s1 = X_s1[:split_idx_val_s1], y_s1[:split_idx_val_s1]\n",
    "    X_val_s1, y_val_s1 = X_s1[split_idx_val_s1:split_idx_test_s1], y_s1[split_idx_val_s1:split_idx_test_s1]\n",
    "    X_test_s1, y_test_s1 = X_s1[split_idx_test_s1:], y_s1[split_idx_test_s1:]\n",
    "\n",
    "    print(f\"Train shapes (S1): {X_train_s1.shape}, {y_train_s1.shape}\")\n",
    "    print(f\"Validation shapes (S1): {X_val_s1.shape}, {y_val_s1.shape}\")\n",
    "    print(f\"Test shapes (S1): {X_test_s1.shape}, {y_test_s1.shape}\")\n",
    "\n",
    "\n",
    "# --- Preprocessing for Station 2 (Transformer) ---\n",
    "if 'df_processed_s2' in locals():\n",
    "    print(\"\\nPreprocessing Station 20380357...\")\n",
    "    # Select features and target\n",
    "    features_s2 = df_processed_s2[['nwm_forecast_lead_1', 'nwm_forecast_lead_2']].values # Add more features if available\n",
    "    target_s2 = df_processed_s2['usgs_observation'].values.reshape(-1, 1)\n",
    "\n",
    "    # Scale features and target\n",
    "    scaler_features_s2 = MinMaxScaler()\n",
    "    features_scaled_s2 = scaler_features_s2.fit_transform(features_s2)\n",
    "\n",
    "    scaler_target_s2 = MinMaxScaler()\n",
    "    target_scaled_s2 = scaler_target_s2.fit_transform(target_s2)\n",
    "\n",
    "    # Create sequences (adjust if Transformer needs different input format)\n",
    "    X_s2, y_s2 = create_sequences(features_scaled_s2, target_scaled_s2.flatten(), SEQUENCE_LENGTH)\n",
    "    print(f\"Station 2 - X shape: {X_s2.shape}, y shape: {y_s2.shape}\")\n",
    "\n",
    "    # Split data\n",
    "    split_idx_test_s2 = int(len(X_s2) * (1 - TEST_SIZE))\n",
    "    split_idx_val_s2 = int(split_idx_test_s2 * (1 - VALIDATION_SIZE))\n",
    "\n",
    "    X_train_s2, y_train_s2 = X_s2[:split_idx_val_s2], y_s2[:split_idx_val_s2]\n",
    "    X_val_s2, y_val_s2 = X_s2[split_idx_val_s2:split_idx_test_s2], y_s2[split_idx_val_s2:split_idx_test_s2]\n",
    "    X_test_s2, y_test_s2 = X_s2[split_idx_test_s2:], y_s2[split_idx_test_s2:]\n",
    "\n",
    "    print(f\"Train shapes (S2): {X_train_s2.shape}, {y_train_s2.shape}\")\n",
    "    print(f\"Validation shapes (S2): {X_val_s2.shape}, {y_val_s2.shape}\")\n",
    "    print(f\"Test shapes (S2): {X_test_s2.shape}, {y_test_s2.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5302fb",
   "metadata": {},
   "source": [
    "## Define LSTM Model for Station 21609641\n",
    "Define the LSTM architecture tailored for Station 21609641, including input layers, hidden layers, and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data for Station 1 exists before defining the model\n",
    "if 'X_train_s1' in locals():\n",
    "    input_shape_s1 = (X_train_s1.shape[1], X_train_s1.shape[2]) # (SEQUENCE_LENGTH, num_features)\n",
    "    print(f\"LSTM Input Shape (S1): {input_shape_s1}\")\n",
    "\n",
    "    lstm_model_s1 = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape_s1),\n",
    "            layers.LSTM(64, return_sequences=True), # Hidden layer 1\n",
    "            layers.Dropout(0.2),\n",
    "            layers.LSTM(32), # Hidden layer 2\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(1) # Output layer (predicting one value)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lstm_model_s1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse') # Mean Squared Error loss\n",
    "    lstm_model_s1.summary()\n",
    "else:\n",
    "    print(\"Skipping LSTM model definition: Station 1 data not preprocessed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25b672",
   "metadata": {},
   "source": [
    "## Define Transformer Model for Station 20380357\n",
    "Define the Transformer architecture tailored for Station 20380357, including encoder-decoder layers and attention mechanisms.\n",
    "*Note: This is a simplified Transformer block example. A full implementation might require separate encoder/decoder structures depending on the task.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data for Station 2 exists before defining the model\n",
    "if 'X_train_s2' in locals():\n",
    "    input_shape_s2 = (X_train_s2.shape[1], X_train_s2.shape[2]) # (SEQUENCE_LENGTH, num_features)\n",
    "    print(f\"Transformer Input Shape (S2): {input_shape_s2}\")\n",
    "\n",
    "    # --- Transformer Block Components (Simplified Example) ---\n",
    "    def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "        # Attention and Normalization\n",
    "        x = layers.MultiHeadAttention(\n",
    "            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "        )(inputs, inputs)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(inputs + x) # Add & Norm\n",
    "\n",
    "        # Feed Forward Part\n",
    "        ff_out = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "        ff_out = layers.Dropout(dropout)(ff_out)\n",
    "        ff_out = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(ff_out)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_out) # Add & Norm\n",
    "        return x\n",
    "\n",
    "    # --- Build the Transformer Model ---\n",
    "    def build_transformer_model(\n",
    "        input_shape,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "    ):\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "        x = inputs\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        # Pooling or Flattening before final MLP\n",
    "        x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "        # x = layers.Flatten()(x) # Alternative\n",
    "\n",
    "        # MLP Head\n",
    "        for dim in mlp_units:\n",
    "            x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "            x = layers.Dropout(mlp_dropout)(x)\n",
    "        outputs = layers.Dense(1)(x) # Output layer\n",
    "\n",
    "        return keras.Model(inputs, outputs)\n",
    "\n",
    "    # --- Instantiate the Model ---\n",
    "    transformer_model_s2 = build_transformer_model(\n",
    "        input_shape_s2,\n",
    "        head_size=128,\n",
    "        num_heads=4,\n",
    "        ff_dim=128,\n",
    "        num_transformer_blocks=3,\n",
    "        mlp_units=[64],\n",
    "        dropout=0.1,\n",
    "        mlp_dropout=0.1,\n",
    "    )\n",
    "\n",
    "    transformer_model_s2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "    transformer_model_s2.summary()\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Transformer model definition: Station 2 data not preprocessed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db52c9",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "Train both the LSTM and Transformer models using the training data. Implement early stopping and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13431e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Configuration ---\n",
    "EPOCHS = 50 # Adjust as needed\n",
    "BATCH_SIZE = 32 # Adjust based on memory\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# --- Train LSTM Model (Station 1) ---\n",
    "history_lstm_s1 = None\n",
    "if 'lstm_model_s1' in locals() and 'X_train_s1' in locals():\n",
    "    print(\"\\nTraining LSTM model for Station 21609641...\")\n",
    "    history_lstm_s1 = lstm_model_s1.fit(\n",
    "        X_train_s1, y_train_s1,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_s1, y_val_s1),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1 # Set to 0 for less output, 1 for progress bar, 2 for one line per epoch\n",
    "    )\n",
    "    print(\"LSTM training finished.\")\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history_lstm_s1.history['loss'], label='Training Loss')\n",
    "    plt.plot(history_lstm_s1.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('LSTM Model Training History (Station 1)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping LSTM training: Model or data not available.\")\n",
    "\n",
    "\n",
    "# --- Train Transformer Model (Station 2) ---\n",
    "history_transformer_s2 = None\n",
    "if 'transformer_model_s2' in locals() and 'X_train_s2' in locals():\n",
    "    print(\"\\nTraining Transformer model for Station 20380357...\")\n",
    "    history_transformer_s2 = transformer_model_s2.fit(\n",
    "        X_train_s2, y_train_s2,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val_s2, y_val_s2),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Transformer training finished.\")\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history_transformer_s2.history['loss'], label='Training Loss')\n",
    "    plt.plot(history_transformer_s2.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Transformer Model Training History (Station 2)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping Transformer training: Model or data not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b348a",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "Evaluate the trained models on the test set using metrics such as CC (Correlation Coefficient), RMSE (Root Mean Squared Error), PBIAS (Percent Bias), and NSE (Nash-Sutcliffe Efficiency). Compare results against raw NWM forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation Metrics Functions ---\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "def calculate_cc(y_true, y_pred):\n",
    "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
    "\n",
    "def calculate_pbias(y_true, y_pred):\n",
    "    return 100 * np.sum(y_pred - y_true) / np.sum(y_true)\n",
    "\n",
    "def calculate_nse(y_true, y_pred):\n",
    "    return 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - np.mean(y_true))**2))\n",
    "\n",
    "# --- Evaluate LSTM Model (Station 1) ---\n",
    "results_s1 = {}\n",
    "if 'lstm_model_s1' in locals() and 'X_test_s1' in locals():\n",
    "    print(\"\\nEvaluating LSTM model on Test Set (Station 1)...\")\n",
    "    # Predict on test set (scaled)\n",
    "    y_pred_scaled_s1 = lstm_model_s1.predict(X_test_s1)\n",
    "\n",
    "    # Inverse transform predictions and true values\n",
    "    y_pred_s1 = scaler_target_s1.inverse_transform(y_pred_scaled_s1)\n",
    "    y_true_s1 = scaler_target_s1.inverse_transform(y_test_s1.reshape(-1, 1)) # Reshape y_test back\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse_s1 = calculate_rmse(y_true_s1.flatten(), y_pred_s1.flatten())\n",
    "    cc_s1 = calculate_cc(y_true_s1.flatten(), y_pred_s1.flatten())\n",
    "    pbias_s1 = calculate_pbias(y_true_s1.flatten(), y_pred_s1.flatten())\n",
    "    nse_s1 = calculate_nse(y_true_s1.flatten(), y_pred_s1.flatten())\n",
    "\n",
    "    results_s1['LSTM'] = {'RMSE': rmse_s1, 'CC': cc_s1, 'PBIAS': pbias_s1, 'NSE': nse_s1}\n",
    "    print(f\"LSTM (S1) - Test Metrics:\")\n",
    "    print(f\"  RMSE: {rmse_s1:.4f}\")\n",
    "    print(f\"  CC:   {cc_s1:.4f}\")\n",
    "    print(f\"  PBIAS:{pbias_s1:.4f}%\")\n",
    "    print(f\"  NSE:  {nse_s1:.4f}\")\n",
    "\n",
    "    # Compare with raw NWM (Example: Lead time 1)\n",
    "    # Need to align NWM forecasts with the test set period\n",
    "    test_start_index_s1 = split_idx_test_s1 + SEQUENCE_LENGTH # Adjust index back to original dataframe\n",
    "    nwm_test_s1 = df_processed_s1['nwm_forecast_lead_1'].iloc[test_start_index_s1 : test_start_index_s1 + len(y_true_s1)].values\n",
    "\n",
    "    if len(nwm_test_s1) == len(y_true_s1):\n",
    "        rmse_nwm_s1 = calculate_rmse(y_true_s1.flatten(), nwm_test_s1)\n",
    "        cc_nwm_s1 = calculate_cc(y_true_s1.flatten(), nwm_test_s1)\n",
    "        pbias_nwm_s1 = calculate_pbias(y_true_s1.flatten(), nwm_test_s1)\n",
    "        nse_nwm_s1 = calculate_nse(y_true_s1.flatten(), nwm_test_s1)\n",
    "        results_s1['NWM_Lead1'] = {'RMSE': rmse_nwm_s1, 'CC': cc_nwm_s1, 'PBIAS': pbias_nwm_s1, 'NSE': nse_nwm_s1}\n",
    "        print(f\"\\nNWM Lead 1 (S1) - Test Metrics:\")\n",
    "        print(f\"  RMSE: {rmse_nwm_s1:.4f}\")\n",
    "        print(f\"  CC:   {cc_nwm_s1:.4f}\")\n",
    "        print(f\"  PBIAS:{pbias_nwm_s1:.4f}%\")\n",
    "        print(f\"  NSE:  {nse_nwm_s1:.4f}\")\n",
    "    else:\n",
    "         print(\"\\nWarning: Could not align NWM forecast for comparison (S1). Length mismatch.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping LSTM evaluation: Model or test data not available.\")\n",
    "\n",
    "\n",
    "# --- Evaluate Transformer Model (Station 2) ---\n",
    "results_s2 = {}\n",
    "if 'transformer_model_s2' in locals() and 'X_test_s2' in locals():\n",
    "    print(\"\\nEvaluating Transformer model on Test Set (Station 2)...\")\n",
    "    # Predict on test set (scaled)\n",
    "    y_pred_scaled_s2 = transformer_model_s2.predict(X_test_s2)\n",
    "\n",
    "    # Inverse transform predictions and true values\n",
    "    y_pred_s2 = scaler_target_s2.inverse_transform(y_pred_scaled_s2)\n",
    "    y_true_s2 = scaler_target_s2.inverse_transform(y_test_s2.reshape(-1, 1)) # Reshape y_test back\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse_s2 = calculate_rmse(y_true_s2.flatten(), y_pred_s2.flatten())\n",
    "    cc_s2 = calculate_cc(y_true_s2.flatten(), y_pred_s2.flatten())\n",
    "    pbias_s2 = calculate_pbias(y_true_s2.flatten(), y_pred_s2.flatten())\n",
    "    nse_s2 = calculate_nse(y_true_s2.flatten(), y_pred_s2.flatten())\n",
    "\n",
    "    results_s2['Transformer'] = {'RMSE': rmse_s2, 'CC': cc_s2, 'PBIAS': pbias_s2, 'NSE': nse_s2}\n",
    "    print(f\"Transformer (S2) - Test Metrics:\")\n",
    "    print(f\"  RMSE: {rmse_s2:.4f}\")\n",
    "    print(f\"  CC:   {cc_s2:.4f}\")\n",
    "    print(f\"  PBIAS:{pbias_s2:.4f}%\")\n",
    "    print(f\"  NSE:  {nse_s2:.4f}\")\n",
    "\n",
    "    # Compare with raw NWM (Example: Lead time 1)\n",
    "    test_start_index_s2 = split_idx_test_s2 + SEQUENCE_LENGTH # Adjust index back to original dataframe\n",
    "    nwm_test_s2 = df_processed_s2['nwm_forecast_lead_1'].iloc[test_start_index_s2 : test_start_index_s2 + len(y_true_s2)].values\n",
    "\n",
    "    if len(nwm_test_s2) == len(y_true_s2):\n",
    "        rmse_nwm_s2 = calculate_rmse(y_true_s2.flatten(), nwm_test_s2)\n",
    "        cc_nwm_s2 = calculate_cc(y_true_s2.flatten(), nwm_test_s2)\n",
    "        pbias_nwm_s2 = calculate_pbias(y_true_s2.flatten(), nwm_test_s2)\n",
    "        nse_nwm_s2 = calculate_nse(y_true_s2.flatten(), nwm_test_s2)\n",
    "        results_s2['NWM_Lead1'] = {'RMSE': rmse_nwm_s2, 'CC': cc_nwm_s2, 'PBIAS': pbias_nwm_s2, 'NSE': nse_nwm_s2}\n",
    "        print(f\"\\nNWM Lead 1 (S2) - Test Metrics:\")\n",
    "        print(f\"  RMSE: {rmse_nwm_s2:.4f}\")\n",
    "        print(f\"  CC:   {cc_nwm_s2:.4f}\")\n",
    "        print(f\"  PBIAS:{pbias_nwm_s2:.4f}%\")\n",
    "        print(f\"  NSE:  {nse_nwm_s2:.4f}\")\n",
    "    else:\n",
    "         print(\"\\nWarning: Could not align NWM forecast for comparison (S2). Length mismatch.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Transformer evaluation: Model or test data not available.\")\n",
    "\n",
    "# Store results in a DataFrame for easier comparison\n",
    "results_df_s1 = pd.DataFrame(results_s1)\n",
    "results_df_s2 = pd.DataFrame(results_s2)\n",
    "\n",
    "print(\"\\n--- Evaluation Summary ---\")\n",
    "if not results_df_s1.empty:\n",
    "    print(\"\\nStation 1 (LSTM vs NWM):\")\n",
    "    print(results_df_s1)\n",
    "if not results_df_s2.empty:\n",
    "    print(\"\\nStation 2 (Transformer vs NWM):\")\n",
    "    print(results_df_s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e6180",
   "metadata": {},
   "source": [
    "## Generate Visualizations\n",
    "Create box plots for observed, NWM, and corrected runoff for each lead time. Generate box plots for evaluation metrics across lead times (if multiple lead times were predicted/evaluated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization 1: Time Series Plot of Predictions vs Actuals ---\n",
    "\n",
    "# Station 1 (LSTM)\n",
    "if 'y_true_s1' in locals() and 'y_pred_s1' in locals():\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    # Get corresponding dates from the original dataframe index\n",
    "    test_dates_s1 = df_processed_s1.index[test_start_index_s1 : test_start_index_s1 + len(y_true_s1)]\n",
    "    plt.plot(test_dates_s1, y_true_s1.flatten(), label='True Observations (S1)', color='blue')\n",
    "    plt.plot(test_dates_s1, y_pred_s1.flatten(), label='LSTM Predictions (S1)', color='red', alpha=0.8)\n",
    "    if 'nwm_test_s1' in locals() and len(nwm_test_s1) == len(y_true_s1):\n",
    "         plt.plot(test_dates_s1, nwm_test_s1, label='NWM Forecast Lead 1 (S1)', color='green', alpha=0.6, linestyle='--')\n",
    "    plt.title('Station 21609641: LSTM Forecast vs Actual Runoff (Test Set)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Runoff')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Station 2 (Transformer)\n",
    "if 'y_true_s2' in locals() and 'y_pred_s2' in locals():\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    test_dates_s2 = df_processed_s2.index[test_start_index_s2 : test_start_index_s2 + len(y_true_s2)]\n",
    "    plt.plot(test_dates_s2, y_true_s2.flatten(), label='True Observations (S2)', color='blue')\n",
    "    plt.plot(test_dates_s2, y_pred_s2.flatten(), label='Transformer Predictions (S2)', color='red', alpha=0.8)\n",
    "    if 'nwm_test_s2' in locals() and len(nwm_test_s2) == len(y_true_s2):\n",
    "         plt.plot(test_dates_s2, nwm_test_s2, label='NWM Forecast Lead 1 (S2)', color='green', alpha=0.6, linestyle='--')\n",
    "    plt.title('Station 20380357: Transformer Forecast vs Actual Runoff (Test Set)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Runoff')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Visualization 2: Box Plots (Example for Station 1) ---\n",
    "# This requires predictions for multiple lead times or grouping data somehow (e.g., by season)\n",
    "# For simplicity, let's just plot the distribution of errors\n",
    "\n",
    "if 'y_true_s1' in locals() and 'y_pred_s1' in locals():\n",
    "    errors_lstm_s1 = y_true_s1.flatten() - y_pred_s1.flatten()\n",
    "    plot_data = {'LSTM Errors (S1)': errors_lstm_s1}\n",
    "    if 'nwm_test_s1' in locals() and len(nwm_test_s1) == len(y_true_s1):\n",
    "        errors_nwm_s1 = y_true_s1.flatten() - nwm_test_s1\n",
    "        plot_data['NWM Errors (S1)'] = errors_nwm_s1\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=pd.DataFrame(plot_data))\n",
    "    plt.title('Distribution of Prediction Errors (Station 1)')\n",
    "    plt.ylabel('Error (True - Predicted)')\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "# Add similar box plot for Station 2 if data is available\n",
    "if 'y_true_s2' in locals() and 'y_pred_s2' in locals():\n",
    "    errors_transformer_s2 = y_true_s2.flatten() - y_pred_s2.flatten()\n",
    "    plot_data_s2 = {'Transformer Errors (S2)': errors_transformer_s2}\n",
    "    if 'nwm_test_s2' in locals() and len(nwm_test_s2) == len(y_true_s2):\n",
    "        errors_nwm_s2 = y_true_s2.flatten() - nwm_test_s2\n",
    "        plot_data_s2['NWM Errors (S2)'] = errors_nwm_s2\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=pd.DataFrame(plot_data_s2))\n",
    "    plt.title('Distribution of Prediction Errors (Station 2)')\n",
    "    plt.ylabel('Error (True - Predicted)')\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Visualization 3: Metrics Comparison (Bar Chart) ---\n",
    "if not results_df_s1.empty:\n",
    "    results_df_s1.plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title('Evaluation Metrics Comparison (Station 1)')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if not results_df_s2.empty:\n",
    "    results_df_s2.plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title('Evaluation Metrics Comparison (Station 2)')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Add more visualizations as needed (e.g., scatter plots of true vs predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2ed97",
   "metadata": {},
   "source": [
    "## Compare Model Performance\n",
    "Analyze and compare the performance of LSTM and Transformer models for both stations. Highlight differences in behavior and accuracy based on the evaluation metrics and visualizations.\n",
    "\n",
    "**Station 21609641 (LSTM):**\n",
    "*   Analyze the LSTM model's performance based on RMSE, CC, PBIAS, NSE compared to the raw NWM forecast.\n",
    "*   Discuss the shape of the error distribution (from box plot). Is there bias? How wide is the spread?\n",
    "*   Examine the time series plot: Does the LSTM capture peaks and troughs better than NWM? Are there lags?\n",
    "\n",
    "**Station 20380357 (Transformer):**\n",
    "*   Analyze the Transformer model's performance similarly.\n",
    "*   Compare its metrics to the raw NWM forecast for this station.\n",
    "*   Discuss its error distribution and time series behavior.\n",
    "\n",
    "**Overall Comparison:**\n",
    "*   Which model type performed better overall, considering the metrics? (Note: They are applied to different stations here, so direct comparison is tricky unless the stations/data are very similar).\n",
    "*   Did one model type show specific strengths (e.g., capturing extremes, lower bias)?\n",
    "*   Relate performance differences to potential characteristics of the data for each station or the inherent differences between LSTM (sequential processing) and Transformer (attention mechanism) architectures.\n",
    "*   Discuss potential reasons for observed performance (e.g., data quality, sequence length choice, model complexity).\n",
    "*   Suggest future improvements or experiments (e.g., hyperparameter tuning, different features, longer sequences, different model variants)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
